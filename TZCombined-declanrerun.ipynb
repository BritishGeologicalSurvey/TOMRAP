{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tanzania hazard map\n",
    "\n",
    "This notebook takes different shape inputs and combines them to create a hazard vulnerability map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expofile = \"TZA_buildings_exposure_20200224.dbf\" #contains location id and positions\n",
    "\n",
    "DATADIR = \"datadir/\"\n",
    "# The one above is not found in the data folder - DV added on Friday - was in the other folder\n",
    "#expofile = DATADIR + \"TZA_buildings_exposure_20200731.dbf\" #contains location id and positions  - present\n",
    "expofile = DATADIR + \"TZA_buildings_exposure_20200224.dbf\" #contains location id and positions  - present\n",
    "#exposure\n",
    "\n",
    "# exposure with breakdown\n",
    "# present\n",
    "expobfile = DATADIR + \"TZA_buildings_exposure_breakdown_20200731.dbf\" #contains location id and breakdown of number of each house type\n",
    "#volcP = [\"kyejo\", \"meru\"]\n",
    "#volcL = [\"lengai\", \"ngozi\", \"rungwe\"]\n",
    "# present\n",
    "volcfile = DATADIR + \"World_Volcanoes_Smithsonian_Institution_GVP.shp\" #point locations of volcanoes\n",
    "volcnames = [\"Lengai, Ol Doinyo\", \"Meru\", \"Ngozi\", \"Rungwe\", \"Kyejo\"] #names of volcanoes in Smithsonian shp\n",
    "\n",
    "# 1 in 100, 1 in 200 in the file\n",
    "floodratio = 100 #selects from different flood tifs\n",
    "floodtypes = [\"FD\", \"FU\", \"P\"] #selects from different flood tifs\n",
    "# in the Seismic folder\n",
    "eqfile = DATADIR + \"hazard_map_mean_tanzania.dbf\" #contains earthquake information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set out imports and functions to use later\n",
    "\n",
    "*dbf_to_df* reads a dbf file, and converts it to a pandas dataframe\n",
    "\n",
    "*getbreakdown* does dbf_to_df, then selects the OBJECTID, CONTYPE, and TOT_CNT columns to create a table where the columns are the CONTYPE (building type), and the values in the table are the counts. (If there are two values for an OBJECTID-CONTYPE pair then the maximum is used, missing values are filled with 0s.) Row sums are calculated, then divided so that the total of each row is 1, so values are proportions of each building type per location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gdal\n",
    "\n",
    "def dbf_to_df(filename):\n",
    "    return pd.DataFrame(gpd.read_file(filename))\n",
    "    \n",
    "    \n",
    "def getbreakdown(filename):\n",
    "    breakdwn = (dbf_to_df(filename)[['OBJECTID', 'CONTYPE', 'TOT_CNT']]\n",
    "        .pivot_table(index='OBJECTID', columns='CONTYPE', values='TOT_CNT', aggfunc=np.max).fillna(0))\n",
    "    breakdwn['SUM'] = breakdwn.sum(axis=1)\n",
    "    breakdwn = breakdwn.divide(breakdwn['SUM'], axis=0).drop('SUM', axis=1)\n",
    "    return breakdwn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volcano\n",
    "\n",
    "Load and combine the volcano shp files.\n",
    "\n",
    "pyroclastic: set to 5 if under 15km from volcano centre, 3 if 15-30km, 1 if 30-50km\n",
    "\n",
    "lahar: set to 5 if under 50km from volcano centre, 3 if 50-100km, 1 if 100-200km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "volcs = gpd.read_file(volcfile)\n",
    "volcs = volcs[volcs.Volc_Name.isin(volcnames)]\n",
    "def to_bdy(gdf):\n",
    "    gdfg = gdf.geometry.unary_union   # geo df geometry\n",
    "    return gpd.GeoDataFrame(geometry=[gdfg], crs=gdf.crs)\n",
    "\n",
    "#generate circles with buffer to get each radius, then take difference for each assignment\n",
    "#pyroclastic\n",
    "# Indexes - get set later on - how close to volcano\n",
    "volcsP5 = to_bdy(volcs.to_crs(\"EPSG:32634\").buffer(15000).to_crs(\"EPSG:4326\"))    # Highest hazard - closest \n",
    "volcsP3 = to_bdy(volcs.to_crs(\"EPSG:32634\").buffer(30000).to_crs(\"EPSG:4326\"))\n",
    "volcsP1 = to_bdy(volcs.to_crs(\"EPSG:32634\").buffer(50000).to_crs(\"EPSG:4326\"))\n",
    "\n",
    "volcsP1 = gpd.overlay(volcsP1, volcsP3, how='difference') #P1 is 50km circle WITHOUT 30km circle\n",
    "volcsP3 = gpd.overlay(volcsP3, volcsP5, how='difference') \n",
    "\n",
    "#lahar\n",
    "volcsL5 = to_bdy(volcs.to_crs(\"EPSG:32634\").buffer(50000).to_crs(\"EPSG:4326\"))\n",
    "volcsL3 = to_bdy(volcs.to_crs(\"EPSG:32634\").buffer(100000).to_crs(\"EPSG:4326\"))\n",
    "volcsL1 = to_bdy(volcs.to_crs(\"EPSG:32634\").buffer(200000).to_crs(\"EPSG:4326\"))\n",
    "\n",
    "volcsL1 = gpd.overlay(volcsL1, volcsL3, how='difference')\n",
    "volcsL3 = gpd.overlay(volcsL3, volcsL5, how='difference')\n",
    "\n",
    "#volcsL = gpd.GeoDataFrame(volcsL1, volcsL3, volcsL5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "volcsL1['lah'] = 1. #set values before combining\n",
    "volcsL3['lah'] = 3.\n",
    "volcsL5['lah'] = 5.\n",
    "volcsP1['pyr'] = 1.\n",
    "volcsP3['pyr'] = 3.\n",
    "volcsP5['pyr'] = 5.\n",
    "\n",
    "volcsL = volcsL1.append(volcsL3).append(volcsL5) #combine all Lahar together\n",
    "volcsP = volcsP1.append(volcsP3).append(volcsP5) # combine pyro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old code (used shp files for volcano basins)\n",
    "def to_bdy(gdf):\n",
    "    gdfg = gdf.geometry.unary_union\n",
    "    return gpd.GeoDataFrame(geometry=[gdfg], crs=gdf.crs)\n",
    "\n",
    "\n",
    "for nam in volcP:\n",
    "    filenam1 = \"%s_30km_basins.shp\" %nam\n",
    "    filenam2 = \"%s_100km_basins.shp\" %nam\n",
    "    \n",
    "    shp1 = to_bdy(gpd.read_file(filenam1))\n",
    "    shp2 = to_bdy(gpd.read_file(filenam2))\n",
    "    \n",
    "    shp1 = shp1.append(shp2).assign(rad=[30.,100.], vol=nam)\n",
    "    \n",
    "    if nam==volcP[0]:\n",
    "        volcall = shp1\n",
    "    else:\n",
    "        volcall = volcall.append(shp1)\n",
    "    \n",
    "volcallP30 = to_bdy(volcall[volcall.rad==30.])\n",
    "volcallP100 = to_bdy(volcall[volcall.rad==100.])\n",
    "\n",
    "volcallP100 = gpd.GeoDataFrame(volcallP100.difference(volcallP30)).rename(columns={0:'geometry'}).set_geometry('geometry')\n",
    "\n",
    "for nam in volcL:\n",
    "    filenam1 = \"%s_30km_basins.shp\" %nam\n",
    "    filenam2 = \"%s_100km_basins.shp\" %nam\n",
    "    \n",
    "    shp1 = to_bdy(gpd.read_file(filenam1))\n",
    "    shp2 = to_bdy(gpd.read_file(filenam2))\n",
    "    \n",
    "    shp1 = shp1.append(shp2).assign(rad=[30.,100.], vol=nam)\n",
    "    \n",
    "    if nam==volcL[0]:\n",
    "        volcall = shp1\n",
    "    else:\n",
    "        volcall = volcall.append(shp1)\n",
    "    \n",
    "volcallL30 = to_bdy(volcall[volcall.rad==30.])\n",
    "volcallL100 = to_bdy(volcall[volcall.rad==100.])\n",
    "\n",
    "volcallL100 = gpd.GeoDataFrame(volcallL100.difference(volcallL30)).rename(columns={0:'geometry'}).set_geometry('geometry')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the exposure files and combine to give building percentages and geometry (don't combine until after multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tzb = getbreakdown(expobfile)   # b - buildings/breakdown    - tz - Tanzania\n",
    "\n",
    "tzg = dbf_to_df(expofile)     # has geometry in it\n",
    "\n",
    "#tzb.to_csv(\"tzb_breakdown.csv\")\n",
    "#tzg.to_csv(\"tzg.csv\")\n",
    "\n",
    "#tz = tzb.merge(tzg.set_index(\"OBJECTID\")[\"geometry\"], how=\"left\", on=\"OBJECTID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiply building percentages with set values and sum per location, tzb must have the building type names as columns and match the building_type_tz array.  \n",
    "\n",
    "Combine with location id and positions to give tz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_type_tz = ['CR/LFM/HBET:1,3',\n",
    "                    'CR/LFM/HBET:4,7',\n",
    "                    'CR/LFM/HBET:8,20',\n",
    "                    'CR/LFINF+DNO/HBET:1,3',\n",
    "                    'CR/LFINF+DNO/HBET:4,7', \n",
    "                    'CR/LFINF+DNO/HBET:8,20',\n",
    "                    'S',                     \n",
    "                    'MUR+CB99/HBET:1,3',\n",
    "                    'MUR+CB99/HBET:4,7',\n",
    "                    'W',\n",
    "                    'MATO/LN', \n",
    "                    'MUR+ADO/HBET:1,3',\n",
    "                    'MUR+CL99', \n",
    "                    'MUR+STRUB',\n",
    "                     'W+WWD']\n",
    "# Numbers could be no. of floors\n",
    "# Could be made more general. Could be different in UK for e.g.\n",
    "\n",
    "# Weightings for each building per hazard type\n",
    "tz_pluvial = [0.32, 0.2, 0.12, 0.4, 0.25, 0.15, 0.09, 0.4, 0.25, 0.8, 0.56, 0.56, 0.56, 0.56, 0.56]\n",
    "tz_fluvial = tz_pluvial\n",
    "tz_tephra = [0.3, 0.15, 0.09, 0.4, 0.2, 0.12, 0.09, 0.5, 0.25, 0.2, 0.6, 0.6, 0.6, 0.6, 0.6]\n",
    "tz_lahar = [0.06, 0.1, 0.06, 0.6, 0.3, 0.18, 0.3, 0.4, 0.2, 1, 1, 1, 1, 1, 1]\n",
    "tz_pyro = [0.56, 0.63, 0.7, 0.64, 0.72, 0.8, 0.9, 0.72, 0.81, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]\n",
    "tz_eq = [0.12, 0.32, 0.16, 0.18, 0.48, 0.24, 0.2, 0.09, 0.24, 0.09, 0.3, 0.3, 0.3, 0.3, 0.3]\n",
    "\n",
    "tzb[\"plu\"] = tzb[building_type_tz].multiply(tz_pluvial).sum(axis=1)\n",
    "tzb[\"flu\"] = tzb[building_type_tz].multiply(tz_fluvial).sum(axis=1)\n",
    "tzb[\"tep\"] = tzb[building_type_tz].multiply(tz_tephra).sum(axis=1) #not currently used\n",
    "tzb[\"lahar\"] = tzb[building_type_tz].multiply(tz_lahar).sum(axis=1)\n",
    "tzb[\"pyro\"] = tzb[building_type_tz].multiply(tz_pyro).sum(axis=1)\n",
    "tzb[\"eq\"] = tzb[building_type_tz].multiply(tz_eq).sum(axis=1)\n",
    "\n",
    "tzb = tzb[[\"plu\", \"flu\", \"tep\", \"lahar\", \"pyro\", \"eq\"]]\n",
    "\n",
    "tz = tzb.merge(tzg.set_index(\"OBJECTID\")[[\"geometry\", \"POINT_X\", \"POINT_Y\"]], how=\"left\", on=\"OBJECTID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood\n",
    "\n",
    "Load in flood files (tifs) and convert them to coordinates of the top corners. Then assign for each location find the tif grid point that location would be in to get the flood value. This can probably be done a lot better.\n",
    "\n",
    "This may need conversion to crs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makecoords(raster):\n",
    "    (xlen, ylen) = (raster.RasterXSize, raster.RasterYSize)\n",
    "    (upper_left_x, x_size, x_rotation, upper_left_y, y_rotation, y_size) = raster.GetGeoTransform()\n",
    "    x_index = np.arange(0,xlen)\n",
    "    y_index = np.arange(0,ylen)\n",
    "    x_coords = x_index * x_size + upper_left_x\n",
    "    y_coords = y_index * y_size + upper_left_y\n",
    "    \n",
    "    return x_coords, y_coords\n",
    "\n",
    "\n",
    "\n",
    "for i in floodtypes:\n",
    "    print(i)\n",
    "    ffile = \"%s_1in%d.tif\" %(i, floodratio)   # flood file\n",
    "    raster = gdal.Open(ffile)\n",
    "    rasterArray = raster.ReadAsArray()\n",
    "    \n",
    "    xco, yco = makecoords(raster)\n",
    "    def getx(xval):\n",
    "        return(np.argmax(xco[xco<xval]))\n",
    "    # nb x and y values go in different directions\n",
    "    def gety(yval):\n",
    "        return(np.argmin(yco[yco>yval]))\n",
    "    if i==floodtypes[0]:\n",
    "        \n",
    "        # For first flood type only - xcoA\n",
    "        # doesn't have to be re run if multiple TIFFS same resolution\n",
    "        xcoA, ycoA = makecoords(raster)\n",
    "        xpts = tzg.POINT_X.map(getx)\n",
    "        ypts = tzg.POINT_Y.map(gety)\n",
    "    else:\n",
    "        if all(xco==xcoA)==False:\n",
    "            print(\"in x false\")\n",
    "            xpts = tzg.POINT_X.map(getx)\n",
    "        if all(yco==ycoA)==False:\n",
    "            print(\"in y false\")\n",
    "            ypts = tzg.POINT_Y.map(gety)\n",
    "    \n",
    "    # set out of range values to 0\n",
    "    rasterArray[rasterArray==-9999.] = 0\n",
    "    rasterArray[rasterArray==999.] = 0\n",
    "    \n",
    "    # Tanzania \n",
    "    \n",
    "    # don't need building weights to work out hazard index\n",
    "    tzg = tzg.assign(fd=rasterArray[xpts, ypts]).rename(columns={'fd':i})\n",
    "    \n",
    "## CRS:\n",
    "\"\"\"\n",
    "Not sure about crs for this -  not enough info other than to use lat/lon\n",
    "\n",
    "have a look in to this\n",
    "\n",
    "tried to put into gdf that contained boxes of the geom - see below\n",
    "\"\"\"\n",
    "\n",
    "# getting x and y can be computationally expensive, so if rasters have same coords can speed up\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the flood values to an index based on the distribution of the values.\n",
    "\n",
    "Out of range -9999. and 999. were set to 0 above. Values of 0 or below are not included when calculating quartiles.\n",
    "\n",
    "Negative or 0 values are set to 0, values in the first quintile are set to 1, ..., values in the top quintile are set to 5.\n",
    "\n",
    "Then merged into tzg, and 'flood' set to 0.5 * (fluvial building weights * fluvial index + pluvial building weights * pluvial index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toindx(pdser):    # pdsr - pandas series\n",
    "    # going from continuous to indexed version\n",
    "    # take values and index them to 1-5 according to quartiles, leave 0s as is\n",
    "    # quartiles/boxes - qs\n",
    "    qs = [-np.inf, 0,\n",
    "          pdser[pdser>0.].quantile(0.2),\n",
    "          pdser[pdser>0.].quantile(0.4),\n",
    "          pdser[pdser>0.].quantile(0.6),\n",
    "          pdser[pdser>0.].quantile(0.8),\n",
    "          pdser[pdser>0.].quantile(1)]\n",
    "    indx = [0,1,2,3,4,5]\n",
    "    return pd.to_numeric(pd.cut(pdser, bins=qs, labels=indx))\n",
    "\n",
    "#convert flood values to (0) 1-5 range\n",
    "\n",
    "for i in floodtypes:\n",
    "    tzg[i] = toindx(tzg[i])\n",
    "\n",
    "tzg = tzg.set_index(\"OBJECTID\").merge(tz)\n",
    "tzg = tzg.assign(flood = lambda x: 0.5*(x.FU * x.flu + x.P * x.plu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine volcano index and building weights\n",
    "\n",
    "volc = 0.45 * (pyro index * pyro building weights) + 0.55 * (lahar index * lahar building weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tzg = gpd.sjoin(gpd.GeoDataFrame(tzg).to_crs(\"EPSG:4326\"), volcsL, op=\"within\", how=\"left\").rename(columns={'index_right':'volcsL'})\n",
    "tzg = gpd.sjoin(tzg, volcsP, op=\"within\", how=\"left\").rename(columns={'index_right':'volcsP'})\n",
    "\n",
    "tzg.loc[np.isnan(tzg.pyr), 'pyr'] = 0.\n",
    "tzg.loc[np.isnan(tzg.lah), 'lah'] = 0.\n",
    "tzg = tzg.assign(volc = lambda x: 0.45*(x.pyr * x.pyro) + 0.55*(x.lah * x.lahar))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old code\n",
    "#tzg = gpd.sjoin(gpd.GeoDataFrame(tzg), volcallP30, op=\"within\", how=\"left\").rename(columns={'index_right':'volcP30'})\n",
    "#tzg = gpd.sjoin(tzg, volcallP100, op=\"within\", how=\"left\").rename(columns={'index_right':'volcP100'})\n",
    "#tzg = gpd.sjoin(tzg, volcallL30, op=\"within\", how=\"left\").rename(columns={'index_right':'volcL30'})\n",
    "#tzg = gpd.sjoin(tzg, volcallL100, op=\"within\", how=\"left\").rename(columns={'index_right':'volcL100'})\n",
    "\n",
    "tzg = gpd.sjoin(gpd.GeoDataFrame(tzg).to_crs(\"EPSG:4326\"), volcsP5, op=\"within\", how=\"left\").rename(columns={'index_right':'volcsP5'})\n",
    "tzg = gpd.sjoin(tzg, volcsP3, op=\"within\", how=\"left\").rename(columns={'index_right':'volcsP3'})\n",
    "tzg = gpd.sjoin(tzg, volcsP1, op=\"within\", how=\"left\").rename(columns={'index_right':'volcsP1'})\n",
    "\n",
    "tzg = gpd.sjoin(tzg, volcsL5, op=\"within\", how=\"left\").rename(columns={'index_right':'volcsL5'})\n",
    "tzg = gpd.sjoin(tzg, volcsL3, op=\"within\", how=\"left\").rename(columns={'index_right':'volcsL3'})\n",
    "tzg = gpd.sjoin(tzg, volcsL1, op=\"within\", how=\"left\").rename(columns={'index_right':'volcsL1'})\n",
    "\n",
    "#this could be done more succinctly\n",
    "#tzg.loc[tzg.volcsP5==0., 'volcsP5'] = 5.\n",
    "\n",
    "#tzg.loc[tzg.volcP30==0., 'volcP30'] = 5.\n",
    "#tzg.loc[np.isnan(tzg.volcP30), 'volcP30'] = 0.\n",
    "#tzg.loc[tzg.volcP100==0., 'volcP100'] = 3.\n",
    "#tzg.loc[np.isnan(tzg.volcP100), 'volcP100'] = 0.\n",
    "#tzg.loc[tzg.volcL30==0., 'volcL30'] = 5.\n",
    "#tzg.loc[np.isnan(tzg.volcL30), 'volcL30'] = 0.\n",
    "#tzg.loc[tzg.volcL100==0., 'volcL100'] = 3.\n",
    "#tzg.loc[np.isnan(tzg.volcL100), 'volcL100'] = 0.\n",
    "\n",
    "#tzg = tzg.assign(volc = lambda x: 0.45*((x.volcP30 + x.volcP100)* x.tep) + 0.55*((x.volcL30 + x.volcL100) * x.lah))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tzg.loc[tzg.volcsP5==0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earthquake\n",
    "\n",
    "Load earthquake dbf, convert from points to raster grid, join with tzg to create tzeA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Earthquake - Tanzania\n",
    "tze = dbf_to_df(eqfile)\n",
    "\n",
    "# tr, bl, br   - top right, bottom left/right etc\n",
    "tze = gpd.GeoDataFrame(\n",
    "    tze, geometry=gpd.points_from_xy(tze.lon, tze.lat))\n",
    "tze = tze.assign(tr=tze.geometry.translate(xoff=0.045), bl=tze.geometry.translate(yoff=-0.045), br=tze.geometry.translate(xoff=0.045, yoff=-0.045))\n",
    "tze = tze.assign(poly=tze.apply(func=lambda A: Polygon([A.geometry, A.tr, A.br, A.bl]), axis=1)).drop(['geometry', 'tr', 'bl', 'br'], axis=1)\n",
    "\n",
    "# extra one to work on\n",
    "tzeA = gpd.sjoin(tzg, tze.set_geometry(col='poly', crs=tzg.crs), op=\"within\", how=\"left\").rename(columns={'index_right':'tze'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tzeA.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert PGA_0_1 to index according to quintiles as above. \n",
    "\n",
    "Construct equ = (equ indx * equ building weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tzeA = tzeA.assign(pgaindx = lambda x: toindx(x.PGA_0_1))\n",
    "tzeA = tzeA.rename(columns={'eq':'ear'}).assign(equ = lambda x: x.pgaindx * x.ear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine \n",
    "\n",
    "Combine to hazard map: 0.5*flood + 0.15 * volc + 0.35 * equ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tzeA = tzeA.assign(hmap = lambda x: 0.5*x.flood + 0.15*x.volc + 0.35*x.equ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(tzeA.equ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tzeA.plot(column='equ', markersize=0.1, legend=True)\n",
    "# Stripey area - had to be rearranged first before plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tzeA.volc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tzeA.plot(column='volc', markersize=0.1, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tzeA.flood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tzeA.plot(column='flood', markersize=0.1, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(tzeA.volc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tzeA.hmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tzeA.plot(column='hmap', markersize=0.1, legend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tzeA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tzeA.plot(column='ear', markersize=0.01, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax = tzeA.plot(ax=ax, column='ear', markersize=0.01, legend=True)\n",
    "lims = plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax = tzeA.plot(axes=ax, column='plu', markersize=0.01, legend=True)\n",
    "lims = plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax = tzeA.plot(ax=ax, column='flu', markersize=0.01, legend=True)\n",
    "lims = plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax = tzeA.plot(ax=ax, column='lahar', markersize=0.01, legend=True)\n",
    "lims = plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax = tzeA.plot(ax=ax, column='tep', markersize=0.01, legend=True)\n",
    "lims = plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax = tzeA.plot(ax=ax, column='pgaindx', markersize=0.01, legend=True)\n",
    "lims = plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax = tzeA.plot(ax=ax, column='P', markersize=0.01, legend=True)\n",
    "lims = plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax = tzeA.plot(ax=ax, column='FU', markersize=0.01, legend=True)\n",
    "lims = plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax = tzeA.plot(ax=ax, column='lah', markersize=0.01, legend=True)\n",
    "lims = plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax = tzeA.plot(ax=ax, column='pyr', markersize=0.01, legend=True)\n",
    "lims = plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax = tzeA.plot(ax=ax, column='equ', markersize=0.01, legend=True)\n",
    "lims = plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax = tzeA.plot(ax=ax, column='flood', markersize=0.01, legend=True)\n",
    "lims = plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax = tzeA.plot(ax=ax, column='volc', markersize=0.01, legend=True)\n",
    "lims = plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax = tzeA.plot(ax=ax, column='hmap', markersize=0.01, legend=True)\n",
    "lims = plt.axis('equal')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
